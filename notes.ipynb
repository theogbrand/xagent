{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refer for building sys prompt of instructions, add_timestamp\n",
    "# https://github.com/phidatahq/ai-cookbook/blob/main/arxiv_ai/assistant.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom tool for scraping Reddit Locallama\n",
    "# https://github.com/majacinka/crewai-experiments/blob/main/reddit_newsletter.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence Window method with LlamaIndex\n",
    "# https://colab.research.google.com/drive/1iTJfi-9RtMnCS68a58UPF96ZSae0qiFb?usp=sharing\n",
    "# chunk by sentence, at runtime when match found, fetches before and after sentences (window) that surround matched sentence to give more context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# official HN API\n",
    "# https://github.com/HackerNews/API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could reuse to recursively fetch references from Arxiv \n",
    "# parses references, searches Google for Arxiv ID, pass to Arxiv API to download paper\n",
    "# https://github.com/theogbrand/arxiv-bot/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetune embeddings + Eval\n",
    "# https://colab.research.google.com/drive/1PoIf9GMHxz2TPKqMHZkYtX_RfjFNbvgw"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
